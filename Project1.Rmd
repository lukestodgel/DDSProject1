---
title: "Project 1"
author: "Braden Anderson and Luke Stodgel"
date: "10/8/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Data Imports

```{r echo=FALSE}

library(magrittr)
library(ggplot2)
library(e1071)
library(dplyr)
library(caret)
library(class)
library(tidyverse)
library(maps)
library(mapproj)

beer_df = read.csv("./Beers.csv")

brewery_df = read.csv("./Breweries.csv")

head(brewery_df)
```


## How many breweries are present in each state?

```{r echo=FALSE}

# Count the number of breweries per state.
breweries_per_state <- brewery_df %>% group_by(State) %>% summarize(count = n())

# Rename the count column, and convert to a dataframe.
breweries_per_state <- as.data.frame(rename(breweries_per_state, Breweries=count))

# Trim unnecessary white space from abbreviations in the "State" column.
breweries_per_state$State <- trimws(breweries_per_state$State)

head(breweries_per_state)
```

## How many breweries are present in each state (set up for visualization).

```{r echo=FALSE}

# Dataframe of state abbreviations and full names.
state_name_lookup <- data.frame(State = state.abb, name=state.name)

# Merging to add a column with full state names to breweries_per_state.
breweries_per_state <- merge(state_name_lookup, breweries_per_state)

# adding "region" column name for easy merging with location data.
breweries_per_state$region <- tolower(breweries_per_state$name)

# Get the latitude and longitude coordinates
# for each states boarder.
states <- map_data("state")

# Merge the location data with the count data.
# This will merge on the shared "region" column.
brewery_map <- merge(states, breweries_per_state)

# Order the long, lat according to the "order" column,
# this makes sure the state boarders get drawn correctly.
brewery_map <- brewery_map[order(brewery_map$order),]

##########################################################################################################################
############# This section is just to set up for annotating the top five brewery containing states on the map ############
##########################################################################################################################

# Create a dataframe sorted by number of breweries (state with the most breweries on top).
sorted_num_breweries <- breweries_per_state[order(breweries_per_state$Breweries,decreasing = TRUE),]

# Use head to create a dataframe with just the top 5 rows.
# (Contains the states with the top 5 most breweries in them).
top_5 <- head(sorted_num_breweries, n=5)

# Merge our top 5 states with the location data.
top_5_states <- merge(states, top_5)

# Find coordinates of the center of each state in our top 5.
top_5_state_location <- top_5_states %>% group_by(region) %>% summarize(max_long=max(long),
                                                                        min_long=min(long),
                                                                        center_long=min(long) + (max(long) - min(long))/2,
                                                                        max_lat=max(lat),
                                                                        min_lat=min(lat),
                                                                        center_lat=min(lat) + (max(lat)-min(lat))/2,
                                                                        brewery_count=max(Breweries),
                                                                        group=max(group))

# Convert our data on the top 5 brewery containing states to a dataframe.
top_5_df <- as.data.frame(top_5_state_location)

# Special adjustment for michigan, because the lakes get in the way if you use the center.
# (Scooting the location over to the right of the lakes).
top_5_df[top_5_df["region"] == "michigan", "center_long"] <- top_5_df[top_5_df["region"] == "michigan", "center_long"] + 2

annot <- data.frame(x=top_5_df$center_long,
                    y=top_5_df$center_lat,
                    text=as.character(top_5_df$brewery_count),
                    group=top_5_df$group)


##########################################################################################################################
############################################## End annotation setup section ##############################################
##########################################################################################################################
```

## Question 1: Visualize breweries by state

```{r echo=FALSE, fig.width=10,fig.height=8}

# Plot the heat map, with annotation for the top 5 states.
ggplot(brewery_map, aes(x=long,y=lat, group=group)) +
  geom_polygon(aes(fill=Breweries)) +
  geom_path() + 
  scale_fill_gradientn(colours=rev(heat.colors(12)),na.value="grey90") + 
  geom_text(data=annot, aes(x=x, y=y, label=text)) +
  ggtitle("Breweries by State")+
  xlab("longitude") + 
  ylab("latitude") +
coord_map()

```
## Question 2: Merge beer data with the breweries data

```{r echo=FALSE}

# Merge the beer and brewery data on beer_df.Brewery_id = brewery_df.Brew_ID
combined_df <- merge(x=beer_df,
                     y=brewery_df,
                     by.x="Brewery_id",
                     by.y="Brew_ID")

# Rename the "Name.x" and "Name.y" columns generated by the merge
# to more informative names (Beer_Name and Brewery_Name).
combined_df <- rename(combined_df,
                      Beer_Name=Name.x,
                      Brewery_Name=Name.y)

# View the first few rows of the combined dataset.
head(combined_df)

```

## Question 3: Address the missing values.

```{r echo=FALSE}

library(naniar)

# visualize where the missing values are
gg_miss_var(combined_df)

```

```{r echo=FALSE}

# Display the beers that are missing a "style". (they aren't actually NaNs but they are blank).
# Also note that 3 of the 5 beers that are missing a "style", are also missing
# the "ABV" and "IBU" information. We don't have much info on these three beers at all. 
combined_df[combined_df[,"Style"]== "", ]

#### Investigating the "beers" with missing style
#
#
# CAN'D AID Foundation: This is not a beer. This was a partnership with Oskar brewing company to 
# distribute cans of drinking water to people in need during the COVID-19 pandemic. This was a very
# nice thing to do, but I do not believe it is relavent to a beer and brewery data analysis, and as such
# this observation will be dropped.
#
# The CROWLER: This is also not a beer. The "CROWLER" is a 32oz can than is intended to be a replacement
# for a growler. So yes, it can contain beer, but is not a specific beer by itself. As such, I believe we
# can safely remove this observation without losing any beer information.

#
# Special Release: There is some uncertainty with this observation, as this could possibly be one of several 
# special release beers. However I believe it is reasonable to impute these missing values with the information
# contained at this link: https://www.beeradvocate.com/beer/profile/29745/131821/?ba=dseanv
# sl_style = "American Amber / Red Ale"

#
# OktoberFiesta: https://untappd.com/b/freetail-brewing-co-oktoberfiesta/79567
# oct_fiesta_style = "MÃ¤rzen / Oktoberfest"

#
# Kilt lifter scottish style ale.... its right in the name (Scottish Style), also, see link below.
# https://www.fourpeaks.com/beer/year-round/kilt-lifter/
# kl_style = "Scottish Style"  
  
```


```{r echo=FALSE}

# Based on the above analysis, the following decisions were made:
#
# 1) Remove the crowler and can'd aid observations
# 2) Impute the missing style for the special release, oktoberfiesta and kilt lifer observations with the following:
sl_style = "American Amber / Red Ale"
oct_fiesta_style = "MÃ¤rzen / Oktoberfest"
kl_style = "Scottish Style"

# Oktober
combined_df[combined_df["Beer_ID"] == 2527, "Style"] = oct_fiesta_style

# Kilt
combined_df[combined_df["Beer_ID"] == 1635, "Style"] = kl_style

# special
combined_df[combined_df["Beer_ID"] == 2210, "Style"] = sl_style

# Setup filters to remove crowler and cand_aid observations.
crowler_filter <- combined_df["Beer_ID"] == 1796
cand_aid_filter <- combined_df["Beer_ID"] == 1790
filters <- crowler_filter | cand_aid_filter

# Verify our filters will remove exactly two items.
sum(filters)

# Remove the crowler and cand aid observations
combined_df <- combined_df[!filters,]

# Verify we no longer have any observations with missing style
combined_df[combined_df[,"Style"]== "", ]

```
```{r echo=FALSE}
# Display the number of missing values in the ABV column.
sum(is.na(combined_df[,"ABV"]))

# We currently have 60 beers missing alcohol content information.
```

```{r echo=FALSE}

# Create a dataframe containing the rows where we are missing the ABV value
missing_abv_df <- combined_df[is.na(combined_df[,"ABV"]), ]

# Save the observations with missing ABV values to a csv, so we can manually 
# search the internet and fill in any info we find. 
write.csv(missing_abv_df, "./beers_with_missing_abv.csv")

```


```{r echo=FALSE}
# Read in dataset that contains values we can fill in for missing ABV values (from internet searches).
abv_fillin_df = read.csv("./beers_fillin_abv.csv")

head(abv_fillin_df)
```




```{r echo=FALSE}

# Create filters to subset just the rows where we are missing the alcohol information
# AND where the name is in the list of names we searched the internet for the correct info on.
fillin_filter <- combined_df$Beer_Name %in% abv_fillin_df$Beer_Name
missing_filter <- is.na(combined_df$ABV)
miss_and_found_filter <- fillin_filter & missing_filter

# Impute the missing values with the ones we found.
combined_df[miss_and_found_filter, "ABV"] <- abv_fillin_df$ABV

# Check how many beers are now missing alcohol content.
# Ten, not bad! we started with 60!
sum(is.na(combined_df$ABV))
```

```{r echo=FALSE}

# Special Release was one we looked up before, this should have been filled in earlier.
# The rest of the beers were very difficult to find any info on (many are special year brews)!
combined_df[is.na(combined_df$ABV),]

# Take care of imputing the special release beer at 7% alcohol.
combined_df[combined_df["Beer_ID"]==2210, "ABV"] = 0.07

# Take one more look at the beers with missing alcohol content, down to 9 of them!
combined_df[is.na(combined_df$ABV),]

```


```{r echo=FALSE}

# To take care of these last 9 beers with missing alcohol content, we will perform the following:
#
# Based on the domain knowledge that alcohol content of a beer is related to its style, we could compute the average
# alcohol content for each style and impute accordingly. However, there may be some higher risk associated with underestimating
# a beers alcohol content. If the alcohol content is underestimated, someone may over-drink and have negative consequences. 
# Therefore, we can take the conservative estimate of computing the maximum alcohol content per beer style, and use these
# values to impute the 9 beers with missing alcohol content information.

max_alch_by_style <- combined_df[!is.na(combined_df[,"ABV"]),] %>% group_by(Style) %>% summarize(max_alch=max(ABV))

max_alch_by_style <- as.data.frame(max_alch_by_style)

head(max_alch_by_style)

```


```{r echo=FALSE}

# Grab the beer ids for the remaining beers missing alcohol content info.
beers_missing_abv <- combined_df[is.na(combined_df$ABV), "Beer_ID"]

# For each beer_id in the list of beer_ids for beers missing ABV... 
for(beer_id in beers_missing_abv){
  
  # Grab the style of that beer.
  style <- combined_df[combined_df["Beer_ID"] == beer_id, "Style"]
  
  # Use our style --> max_alch map to get the max_alch for this beer style.
  max_alch <- max_alch_by_style[max_alch_by_style[,"Style"] == style, "max_alch"]
  
  # Update the ABV for this beer to the max alch for the associated beer style
  combined_df[combined_df["Beer_ID"] == beer_id, "ABV"] <- max_alch
  
}

# Verify that we now have ZERO missing values in the ABV column.
sum(is.na(combined_df$ABV))

```


```{r echo=FALSE}

# Check how many missing values we have in the IBU column
sum(is.na(combined_df$IBU))

```

```{r echo=FALSE}

# Following a similar template as established above, we will now calculate the average IBU rating for each 
# beer style, and then will impute missing IBU values using the mean IBU for the associated style.
#
#

# Calculate mean IBU for each beer style.
mean_ibu_by_style <- combined_df[!is.na(combined_df[,"IBU"]),] %>% group_by(Style) %>% summarize(avg_ibu=mean(IBU))

# Convert to dataframe.
mean_ibu_by_style <- as.data.frame(mean_ibu_by_style)

# Take a look at the first few rows
head(mean_ibu_by_style)

```

```{r echo=FALSE}

# Grab the beer ids for the beers missing IBU information
beers_missing_ibu <- combined_df[is.na(combined_df$IBU), "Beer_ID"]

# Global IBU mean for last resort fill in (see if statement inside for loop).
global_mean_IBU <- mean(combined_df[!is.na(combined_df$IBU),"IBU"])

# For each beer_id in the list of beer_ids for beers missing ABV... 
for(beer_id in beers_missing_ibu){
  
  # Grab the style of that beer.
  style <- combined_df[combined_df["Beer_ID"] == beer_id, "Style"]
  
  # Use our style --> average_IBU map to get the average IBU rating for this beer style.
  average_ibu <- mean_ibu_by_style[mean_ibu_by_style[,"Style"] == style, "avg_ibu"]
  
  # Last resort, if average_ibu is length zero, which means there is no other beers with this style
  # to take an IBU average over.... in this case, fill in with the global average IBU rating.
  # else, fill in with the mean within the associated style.
  if(length(average_ibu) == 0){
    
    combined_df[combined_df["Beer_ID"] == beer_id, "IBU"] <- global_mean_IBU
    
  }else{
  
    combined_df[combined_df["Beer_ID"] == beer_id, "IBU"] <- average_ibu   
    
  }
  
}

# Verify that we now have ZERO missing values in the IBU column.
sum(is.na(combined_df$IBU))

```

```{r echo=FALSE}
# visualize the missing values one more time, verify there are now zero missing values in all columns.
gg_miss_var(combined_df)


```

## Question 4: Compute the median alcohol content and IBUs for each state.
## Plot a bar chart to compare. 

```{r echo=FALSE}

medians_by_state <- combined_df %>% group_by(State) %>% summarize(median_abv=median(ABV),
                                                                  median_ibu=median(IBU))

medians_by_state <- as.data.frame(medians_by_state)

head(medians_by_state)

```


```{r echo=FALSE}

# Barplot of median alcohol content by state
ggplot(data=medians_by_state) + 
  geom_bar(stat='identity', mapping=aes(x=reorder(State, median_abv), y=median_abv), fill="aquamarine4", color="navy") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + 
  xlab("State") + 
  ylab("Median Alcohol Content of Beers") + 
  ggtitle("Median Alcohol Content in Beers by State")

```


```{r echo=FALSE}

# Barplot of median IBU by state
ggplot(data=medians_by_state) + 
  geom_bar(stat='identity', mapping=aes(x=reorder(State, median_ibu), y=median_ibu), fill="deeppink3", color="navy") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + 
  xlab("State") + 
  ylab("Median IBU Rating of Beers") + 
  ggtitle("Median IBU Rating of Beers by State")

```

## Question 5: Which state has the maximum alcoholic (ABV) beer? 
##             Which state has the most bitter (IBU) beer?

```{r}

# Which state has the maximum alcoholic (ABV) beer?
# Step 1 find highest ABV
maxABV <- max(combined_df$ABV, na.rm = TRUE)

# Step 2 get Brewery_ID using max ABV
maxABVBreweryID = combined_df %>% filter(ABV == maxABV) %>% select(Brewery_id)
maxABVBreweryID = as.integer(maxABVBreweryID) # 52 - Upslope Brewing Company. What a coincidence my brother's old room mate used to work here when they lived in Boudler, CO.

# Step 3 find state using maxABVBreweryID
combined_df %>% filter(Brewery_id == maxABVBreweryID) %>% select(State)
#
# It's Colorado (12.8% ABV) - Lee Hill Series Vol. 5 - Belgian Style Quadrupel Ale - 
# Upslope Brewing Company, Boulder, CO.


# Step 1 find highest IBU
maxIBU <- max(combined_df$IBU, na.rm = TRUE)

# Step 2 get Brewery_id using max IBU
maxIBUBreweryID = combined_df %>% filter(IBU == maxIBU) %>% select(Brewery_id)
maxIBUBreweryID = as.integer(maxIBUBreweryID)

# Step 3 find state using maxIBUBreweryID 
combined_df %>% filter(Brewery_id == maxIBUBreweryID) %>% select(State)
#
# It's Oregon (138 IBU) - Bitter Bitch Imperial IPA - American Double / Imperial IPA 
# Astoria Brewing Company, Astoria, OR.
```

## Question 6: Comment on the summary statistics and distribution 
##             of the ABV variable.

```{r echo = FALSE}

summary(combined_df$ABV)
# The beer with the lowest ABV has .1%, Q1 has 5%, the median is 5.6%, Q3 has 6.7%, the mean percentage ABV is 5.98, and the highest ABV is 12.8%
# There is definitely a large difference in ABV between the min and the max values.
# Below is a plot of numBeers categorized by ABV. By plotting all of the beers with respect to their ABV in a bar chart, we can see that this data is right skewed. A large portion of the beers are within the 4.5-6.25% ABV range.

combined_df %>% 
  ggplot(aes(x = ABV)) + 
  geom_histogram() + 
  ggtitle("Num Beers at each ABV")
# Histogram plotting number of beers at their respective ABV.

```

## Question 7: Is there an apparent relationship between the bitterness of the 
##             beer and its alcoholic content? Draw a scatter plot.  

##             Make your best judgment of a relationship and 
##             EXPLAIN your answer.

```{r echo = FALSE}

combined_df %>% 
  select(IBU, ABV) %>% 
  ggplot(aes(x = ABV, y = IBU)) + 
  geom_point() +
  geom_smooth(method='lm') +
  ggtitle("IBU Vs. ABV")
# According to the chart, it looks like there is a relationship between IBU and ABV. The trend looks like as ABV increases, so does IBU. 
# Some outliers do exist; For example the beer with the highest ABV does not have the highest IBU, and beer with the lowest ABV does not have the lowest IBU. 
# It looks like the largest cluster of beers in this chart is within the 3.75%-6.25% ABV and 12.5-50 IBU range.

```

## Question 8: Budweiser would also like to investigate the difference with 
##             respect to IBU and ABV between IPAs (India Pale Ales) and other 
##             types of Ale (any beer with “Ale” in its name other than IPA).

##             You decide to use KNN classification to investigate this 
##             relationship.  Provide statistical evidence one way or the other. 

##             You can of course assume your audience is comfortable with 
##             percentages … KNN is very easy to understand conceptually.

##             In addition, while you have decided to use KNN to investigate 
##             this relationship (KNN is required) you may also feel free to 
##             supplement your response to this question with any other methods 
##             or techniques you have learned.  Creativity and alternative 
##             solutions are always encouraged. 

```{r echo = FALSE}
##################
# Knn.cv for IPAs#
##################
# Testing to see if knn.cv can correctly identify the Style of beer based on ABV and IBU

# extract only beers with style "IPA"
beerIPA = combined_df %>% filter(grepl("IPA",Style))
beerIPA = droplevels(beerIPA,exclude = !beerIPA)

set.seed(1)
iterations = 100
numks = 50

masterAccIPA = matrix(nrow = iterations, ncol = numks)

for(j in 1:iterations)
{
  
  for(i in 1:numks)
  {
    CM = confusionMatrix(table(beerIPA[,6],knn.cv(beerIPA[,c(4,5)],beerIPA[,6],k = i)))
    masterAccIPA[j,i] = CM$overall[1]
  }
  
}

# use the 50 accuracies from each test in the for-loop  above and store it in MeanAccIPA
MeanAccIPA = colMeans(masterAccIPA)

# plot each accuracy at each K value
plot(seq(1,numks,1),MeanAccIPA)

which.max(MeanAccIPA)

confusionMatrix(table(beerIPA[,6],knn.cv(beerIPA[,c(4,5)],beerIPA[,6],k = 1))) # accuracy = 0.9159
confusionMatrix(table(beerIPA[,6],knn.cv(beerIPA[,c(4,5)],beerIPA[,6],k = 4))) # accuracy = 0.9177
confusionMatrix(table(beerIPA[,6],knn.cv(beerIPA[,c(4,5)],beerIPA[,6],k = 10))) # accuracy = 0.8844
confusionMatrix(table(beerIPA[,6],knn.cv(beerIPA[,c(4,5)],beerIPA[,6],k = 20))) # accuracy = 0.8336


##################
# Knn.cv for Ales#
##################

# extract only beers with style "Ale" and not with "IPA"
beerAle = combined_df %>% filter(grepl("Ale",Style) & !grepl("IPA",Style))
beerAle = droplevels(beerAle,exclude = !beerAle)

set.seed(1)
iterations = 100
numks = 50

masterAccAle = matrix(nrow = iterations, ncol = numks)

for(j in 1:iterations)
{
  
  for(i in 1:numks)
  {
    CM = confusionMatrix(table(beerAle[,6],knn.cv(beerAle[,c(4,5)],beerAle[,6],k = i)))
    masterAccAle[j,i] = CM$overall[1]
  }
  
}

# use the 50 accuracies from each test in the for-loop  above and store it in MeanAccAle
MeanAccAle = colMeans(masterAccAle)

# plot each accuracy at each K value
plot(seq(1,numks,1),MeanAccAle)

which.max(MeanAccAle)

confusionMatrix(table(beerAle[,6],knn.cv(beerAle[,c(4,5)],beerAle[,6],k = 1))) # accuracy = 0.6691
confusionMatrix(table(beerAle[,6],knn.cv(beerAle[,c(4,5)],beerAle[,6],k = 5))) # accuracy = 0.6525
confusionMatrix(table(beerAle[,6],knn.cv(beerAle[,c(4,5)],beerAle[,6],k = 10))) # accuracy = 0.6245
confusionMatrix(table(beerAle[,6],knn.cv(beerAle[,c(4,5)],beerAle[,6],k = 20))) # accuracy = 0.5902
#The best accuracy for IPAs was 91.77% and for Ales it was 66.91%. It is understandable that the Ales did not classify as well as the IPAs considering there is almost twice the amount of data for Ales and also there are 28 different Styles of Ales. IPAs only had 5 unique Styles. K=4 achieved the highest accuracy for IPAs and k=1 provided the best accuracy for Ales.

#shows 28 different Ales
beerAle %>% count(Style)
#shows 5 different IPAs
beerIPA %>% count(Style)

#######################
# NB test on same data#
#######################
#IPAs first

iterations = 95

masterAccNBIPA = matrix(nrow = iterations)

for(j in 1:iterations)
{
  set.seed(j)
  trainIndicies = sample(seq(1:length(beerIPA$Style)),round(.7*length(beerIPA$Style)))
  trainIPA = beerIPA[trainIndicies,]
  testIPA = beerIPA[-trainIndicies,]
  
  model = naiveBayes(trainIPA[,c(4,5)],trainIPA$Style, laplace = 1)
  table(predict(model,testIPA[,c(4,5)]),testIPA$Style)
  CM = confusionMatrix(table(predict(model,testIPA[,c(4,5)]),testIPA$Style))
  
  masterAccNBIPA[j] = CM$overall[1]
}

MeanAccNBIPA = colMeans(masterAccNBIPA)
MeanAccNBIPA
#Mean accuracy here is 89.8% using the Naive Bayes method.

###############
# Testing Ales#
###############
#Beers that only appear once are causing issues within the model. Since this is extra work I will abandon this part. - Luke 

#beerAle = beerAle[grep("Wheat Ale",beerAle$Style,invert = TRUE), ]
#beerAle = beerAle[grep("Flanders Red Ale",beerAle$Style,invert = TRUE),]
#beerAle = beerAle[grep("Old Ale",beerAle$Style,invert = TRUE), ]

#iterations = 10

#masterAccNBAle = matrix(nrow = iterations)

#for(j in 1:iterations)
#{
#  set.seed(j)
#  trainIndicies = sample(seq(1:length(beerAle$Style)),round(.7*length(beerAle$Style)))
#  trainAle = beerAle[trainIndicies,]
#  testAle = beerAle[-trainIndicies,]
  
#  model = naiveBayes(trainAle[,c(4,5)],trainAle$Style, laplace = 1)
#  table(predict(model,testAle[,c(4,5)]),testAle$Style)
#  CM = confusionMatrix(table(predict(model,testAle[,c(4,5)]),testAle$Style))
  
#  masterAccNBAle[j] = CM$overall[1]
#}

#MeanAccNBAle = colMeans(masterAccNBAle)
#MeanAccNBAle

```

## Question 9: Knock their socks off!  Find one other useful inference from the 
##             data that you feel Budweiser may be able to find value in.  
##             You must convince them why it is important and back up your 
##             conviction with appropriate statistical evidence. 

```{r echo = FALSE}
#find states that are lacking breweries and suggest expansion opportunities.

# Count how many breweries are in each state
breweries_per_state <- brewery_df %>% group_by(State) %>% summarize(count = n())

# Put the data frame in ascending order by num Breweries - Bottom 6 states are DC, ND, SD, WV, AR, DE
head(arrange(breweries_per_state, count))

# States with one to four breweries - There are 19 states that have four or fewer breweries. Potential expansion opportunities.
arrange((breweries_per_state %>% filter(count == 1 | count == 2 | count == 3 | count == 4)), count)

# It turns out there are only one or two unique instances of each brewery. So this doesn't mean much to us. I thought if there were breweries that occurred several times that might mean they were popular.
num_occurences_of_breweries <- brewery_df %>% group_by(Name) %>% summarize(count = n())
arrange(num_occurences_of_breweries, desc(count))

# Extra - Put the data frame in descending order by num Breweries - Top 6 states are CO, CA, MI, OR, TX, PA
head(arrange(breweries_per_state, desc(count)))
# Looking at the states with the most breweries and at the states with the least breweries we are suggesting that if the conditions are right, maybe it would be strategic to start up breweries in the states that have fewer breweries.

```
